{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d34a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import csv\n",
    "import distutils.util\n",
    "import distutils\n",
    "import os\n",
    "import Dummy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e64ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Dataset from pandas dataframe to numpy array and dictionary \n",
    "def convert_to_ndarray(data):\n",
    "    data_dict = {}\n",
    "    for column in data.columns:\n",
    "        data_dict[column] = data[column].to_numpy()\n",
    "    data_ndarray = np.column_stack(list(data_dict.values()))\n",
    "    return data_dict,data_ndarray\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4456dd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_scheme = ['Female', 'Male', 'Primate', 'Rodent', 'Food']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "524e55d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"E:/Upwork project/training_data.csv\")\n",
    "test_df = pd.read_csv(\"E:/Upwork project/testing_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21798669",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict , train_ndarray = convert_to_ndarray(train_df)\n",
    "test_dict , test_ndarray = convert_to_ndarray(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "778ac1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateDataFormat(data, predicted):\n",
    "    # Define the classification scheme\n",
    "#     classification_scheme = ['Female', 'Male', 'Primate', 'Rodent', 'Food']\n",
    "    for key, value in data.items():\n",
    "        size = value.size\n",
    "    # Check if data is empty\n",
    "    if size == 0:\n",
    "        return False\n",
    "\n",
    "    # Check if the required columns are present\n",
    "    if predicted:\n",
    "        required_columns = [\"Path\", \"ActualClass\", \"PredictedClass\"]\n",
    "    else:\n",
    "        required_columns = [\"Path\", \"ActualClass\"]\n",
    "    if not all(col in data.keys() for col in required_columns):\n",
    "        return False \n",
    "\n",
    "    # Check if values in the \"Path\" column are file paths\n",
    "    if not all(isinstance(path, str) for path in data[\"Path\"]):\n",
    "        return False\n",
    "\n",
    "    # Check if values in the \"ActualClass\" column are from the classification scheme\n",
    "    if not all(actual_class in classification_scheme for actual_class in data[\"ActualClass\"]):\n",
    "        return False\n",
    "\n",
    "    # Check if values in the \"PredictedClass\" column (if present) are from the classification scheme\n",
    "    if predicted:\n",
    "        if not all(predicted_class in classification_scheme for predicted_class in data[\"PredictedClass\"]):\n",
    "            return False\n",
    "\n",
    "    # Check if the number of entries in \"Path\" matches the number of entries in \"ActualClass\" (and \"PredictedClass\" if predicted is True)\n",
    "    if len(data[\"Path\"]) != len(data[\"ActualClass\"]):\n",
    "        return False\n",
    "    if predicted:\n",
    "        if len(data[\"Path\"]) != len(data[\"PredictedClass\"]):\n",
    "            return False\n",
    "        \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ba8cda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAndResize(image_path, width=60, height=30):\n",
    "   \n",
    "    parts = image_path.split('/')\n",
    "    part1_path = \"E:/Upwork project/images/\"\n",
    "\n",
    "    # Extract the desired part from the second element onwards\n",
    "    desired_part = '/'.join(parts[-2:])\n",
    "    final = part1_path + desired_part\n",
    "    try:\n",
    "        # Open the image file\n",
    "        with Image.open(final) as img:\n",
    "            # Resize the image\n",
    "            resized_img = img.resize((width, height))\n",
    "            # Convert the image to numpy array\n",
    "            image = np.array(resized_img)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Image not found at the given path.\")\n",
    "        # Return an empty array if the image is not found\n",
    "        image = np.array([])\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1beab22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Euclidean Distance \n",
    "def computeMeasure1(image1, image2):\n",
    "    # Write here what kind of measure you are using!\n",
    "     # Check if images are empty\n",
    "    if image1.size == 0 or image2.size == 0:\n",
    "        value = float('nan')\n",
    "        return value\n",
    "\n",
    "\n",
    "    # Check if images have the same shape\n",
    "    if image1.shape != image2.shape:\n",
    "        raise ValueError(\"Input images must have the same shape\")\n",
    "\n",
    "    # Calculate Euclidean distance\n",
    "    distance = np.linalg.norm(image1 - image2)\n",
    "\n",
    "    return distance\n",
    "\n",
    "# Manhattan distance    \n",
    "def computeMeasure2(image1, image2):\n",
    "    # Write here what kind of measure you are using!\n",
    "     # Check if images are empty\n",
    "    if image1.size == 0 or image2.size == 0:\n",
    "        value = float('nan')\n",
    "        return value\n",
    "\n",
    "    # Check if images have the same shape\n",
    "    if image1.shape != image2.shape:\n",
    "        raise ValueError(\"Input images must have the same shape\")\n",
    "    # Calculate Manhattan distance\n",
    "    distance = np.sum(np.abs(image1 - image2))\n",
    "    return distance\n",
    "\n",
    "# cosine similarity\n",
    "def computeMeasure3(image1, image2):\n",
    "    # Write here what kind of measure you are using!\n",
    "    # Check if images are empty\n",
    "    if image1.size == 0 or image2.size == 0:\n",
    "        value = float('nan')\n",
    "        return value\n",
    "\n",
    "    # Check if images have the same shape\n",
    "    if image1.shape != image2.shape:\n",
    "        raise ValueError(\"Input images must have the same shape\")\n",
    "    # Compute dot product and norms without flattening\n",
    "    dot_product = np.sum(image1 * image2)\n",
    "    norm_image1 = np.linalg.norm(image1)\n",
    "    norm_image2 = np.linalg.norm(image2)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity = dot_product / (norm_image1 * norm_image2)\n",
    "\n",
    "    return similarity\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67e616af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# euclidean_distance from scratch\n",
    "def selfComputeMeasure1(image1, image2):\n",
    "    # Write here what kind of measure you are using - it has to correspond to the approach in computeMeasure1\n",
    "        # Check if images are empty\n",
    "    if image1.size == 0 or image2.size == 0:\n",
    "        value = float('nan')\n",
    "    return value\n",
    "\n",
    "    # Check if images have the same shape\n",
    "    if image1.shape != image2.shape:\n",
    "        raise ValueError(\"Input images must have the same shape\")\n",
    "\n",
    "    # Initialize squared differences\n",
    "    squared_diff_sum = 0\n",
    "\n",
    "    # Iterate through pixels and calculate squared differences\n",
    "    for i in range(image1.shape[0]):\n",
    "        for j in range(image1.shape[1]):\n",
    "            for k in range(image1.shape[2]):\n",
    "                squared_diff_sum += (image1[i, j, k] - image2[i, j, k]) ** 2\n",
    "\n",
    "    # Compute square root of the sum of squared differences\n",
    "    euclidean_distance = np.sqrt(squared_diff_sum)\n",
    "\n",
    "    return euclidean_distance\n",
    "\n",
    "# manhattan_distance from scratch\n",
    "def selfComputeMeasure2(image1, image2):\n",
    "    # Write here what kind of measure you are using - it has to correspond to the approach in computeMeasure2\n",
    "    # Check if images are empty\n",
    "    if image1.size == 0 or image2.size == 0:\n",
    "        value = float('nan')\n",
    "\n",
    "    return value\n",
    "\n",
    "    # Check if images have the same shape\n",
    "    if image1.shape != image2.shape:\n",
    "        raise ValueError(\"Input images must have the same shape\")\n",
    "\n",
    "    # Initialize Manhattan distance\n",
    "    manhattan_distance = 0\n",
    "\n",
    "    # Iterate through pixels and calculate Manhattan distance\n",
    "    for i in range(image1.shape[0]):\n",
    "        for j in range(image1.shape[1]):\n",
    "            for k in range(image1.shape[2]):\n",
    "                manhattan_distance += abs(image1[i, j, k] - image2[i, j, k])\n",
    "\n",
    "    return manhattan_distance\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f36fcca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassesOfKNearestNeighbours(measure_classes, k, similarity_flag):\n",
    "    nearest_neighbours_classes = {}\n",
    "\n",
    "    # Sort the measure_classes based on distance or similarity\n",
    "    if similarity_flag ==True:\n",
    "        sorted_measure_classes = sorted(measure_classes, key=lambda x: x[0], reverse=True)\n",
    "    else:\n",
    "        sorted_measure_classes = sorted(measure_classes, key=lambda x: x[0])\n",
    "\n",
    "    # Get the k nearest neighbours\n",
    "    k_nearest_neighbours = sorted_measure_classes[:k]\n",
    "\n",
    "    # Count the occurrences of each class\n",
    "    for measure, class_label in k_nearest_neighbours:\n",
    "        if class_label in nearest_neighbours_classes:\n",
    "            nearest_neighbours_classes[class_label] += 1\n",
    "        else:\n",
    "            nearest_neighbours_classes[class_label] = 0\n",
    "\n",
    "    return nearest_neighbours_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c38c99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMostCommonClass(nearest_neighbours_classes):\n",
    "    winner = 'NaN'\n",
    "     # Check if the input dictionary is empty or if it does not contain any classes from the scheme\n",
    "    if not nearest_neighbours_classes or set(nearest_neighbours_classes.keys()).isdisjoint(classification_scheme):\n",
    "        return winner\n",
    "    \n",
    "    # Check if all classes in the scheme have occurrence of 0\n",
    "    if all(count == 0 for count in nearest_neighbours_classes.values()):\n",
    "        return winner\n",
    "    winner = max(nearest_neighbours_classes, key=nearest_neighbours_classes.get)\n",
    "\n",
    "    return winner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8aad32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN(training_data, k, measure_func, similarity_flag, data_to_classify,getMostCommonClass, getClassesOfKNearestNeighbours,readAndResize12):\n",
    "    # This sets the header list\n",
    "    classified_data = np.array([['Path', 'ActualClass', 'PredictedClass']])\n",
    "    # Iterate over each data point in data_to_classify\n",
    "    for data_point in test_ndarray:\n",
    "        # Extract the path and actual class from the data point\n",
    "        test_path, test_actual_class = data_point[:2]\n",
    "        \n",
    "        # Apply the read_func to read and resize the image (assuming it returns empty array for invalid paths)\n",
    "        test_image = readAndResize12(test_path, width=60, height=30)\n",
    "        \n",
    "        # Check if the image is empty (i.e., path is invalid)\n",
    "        if test_image.size == 0:\n",
    "            continue  # Skip this data point\n",
    "        \n",
    "        # Calculate distances/similarities between the current data point and all data points in training_data\n",
    "        measures_classes = []\n",
    "        for training_point in train_ndarray:\n",
    "            train_path, train_actual_class = training_point[:2]\n",
    "            train_image = readAndResize12(train_path, width=60, height=30)\n",
    "            if train_image.size == 0:\n",
    "                continue  # Skip this train data point\n",
    "             \n",
    "            measure = measure_func(train_image, test_image)\n",
    "            measures_classes.append((measure, train_actual_class)) \n",
    "   \n",
    "            \n",
    "        # Get the classes of k nearest neighbors\n",
    "        nearest_neighbours_classes = getClassesOfKNearestNeighbours(measures_classes, k, similarity_flag)\n",
    "        \n",
    "        # Get the predicted class for the current data point\n",
    "        predicted_class = getMostCommonClass(nearest_neighbours_classes)\n",
    "        \n",
    "        # Append the path, actual class, and predicted class to the classified_data array\n",
    "        classified_data = np.append(classified_data, [[test_path, test_actual_class, predicted_class]], axis=0)\n",
    "    \n",
    "    # Have fun!\n",
    "    \n",
    "    return classified_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf0bb22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_data = kNN(train_ndarray , 11 , computeMeasure2, False , test_ndarray , getMostCommonClass , getClassesOfKNearestNeighbours , readAndResize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "324bb213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Path', 'ActualClass', 'PredictedClass'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0626369.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0081097.jpg',\n",
       "        'Female', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0405408.jpg',\n",
       "        'Female', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0582035.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0090463.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0899088.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0299741.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0083465.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0194016.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0548166.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0671601.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0106948.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0420558.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0295436.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0851563.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0056052.jpg',\n",
       "        'Female', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0960225.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0606532.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0068754.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0212155.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0648836.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0122324.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0478651.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0356958.jpg',\n",
       "        'Female', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0461490.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0920575.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0453626.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0812142.jpg',\n",
       "        'Female', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0739178.jpg',\n",
       "        'Female', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0420867.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0714300.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0007944.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0476276.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0134449.jpg',\n",
       "        'Female', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0798766.jpg',\n",
       "        'Female', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0306577.jpg',\n",
       "        'Female', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0228313.jpg',\n",
       "        'Male', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0255176_0719982_0732799.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0213002.jpg',\n",
       "        'Male', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0917152.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0046068.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0169026.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0090043.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0370445.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0144032.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0339744.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0071675.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0326715.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0310978.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0483893.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0264549.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0604784.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0541995.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0379152.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0681847.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0571571.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0902416.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0185268.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0243391.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0254606.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0374113.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0612463.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0888610.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0072230.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0126061.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0903221.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0379205.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0403430.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0830610.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0334107.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0888692.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0495133.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0675441.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0601778.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0729986.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0898302.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0518848.jpg',\n",
       "        'Male', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0663073.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0788344.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0189705.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0935109.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0033233.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0512907.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0882693.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0672039.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0276569.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0082658.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0500424.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0981385.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0907429.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0281221.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0451804.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0782378.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0669783.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0501819.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0074679.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0862820.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0376918.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0642670.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0462134.jpg',\n",
       "        'Male', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496941714.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496946405.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496961502.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496975736.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496985122.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553497009356.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553497044642.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553497048958.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553497054040.jpg', 'Rodent',\n",
       "        'Primate'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553497083697.jpg', 'Rodent',\n",
       "        'Primate'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553497083990.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553497093075.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553497093214.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553497093311.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553497117565.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553497152015.jpg', 'Rodent',\n",
       "        'Primate'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496397568.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496407209.jpg', 'Rodent',\n",
       "        'Primate'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496422443.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496442129.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496446794.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496519946.jpg', 'Rodent',\n",
       "        'Female'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496529253.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496539345.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496540382.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496568864.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496578568.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496613634.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496637960.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496672123.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496672424.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496672831.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496696581.jpg', 'Rodent',\n",
       "        'Primate'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496706043.jpg', 'Rodent',\n",
       "        'Primate'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496706325.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496711429.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496721699.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496745907.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496755559.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496780048.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496804065.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496804134.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496814069.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496818485.jpg', 'Rodent',\n",
       "        'Primate'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496828072.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496828385.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496843797.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496867646.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496887017.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8_img_1553496926030.jpg', 'Rodent',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496441620.jpg', 'Primate',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496477614.jpg', 'Primate',\n",
       "        'Female'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496487830.jpg', 'Primate',\n",
       "        'Male'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496512465.jpg', 'Primate',\n",
       "        'Female'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496517287.jpg', 'Primate',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496524105.jpg', 'Primate',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496532554.jpg', 'Primate',\n",
       "        'Primate'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496538737.jpg', 'Primate',\n",
       "        'Primate'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496559051.jpg', 'Primate',\n",
       "        'Primate'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496561084.jpg', 'Primate',\n",
       "        'Primate'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496568382.jpg', 'Primate',\n",
       "        'Female'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496586846.jpg', 'Primate',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496589106.jpg', 'Primate',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496601625.jpg', 'Primate',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496612518.jpg', 'Primate',\n",
       "        'Primate'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496638269.jpg', 'Primate',\n",
       "        'Primate'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496638661.jpg', 'Primate',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496640645.jpg', 'Primate',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496650086.jpg', 'Primate',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496661805.jpg', 'Primate',\n",
       "        'Primate'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496665924.jpg', 'Primate',\n",
       "        'Male'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496723343.jpg', 'Primate',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496725979.jpg', 'Primate',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496736185.jpg', 'Primate',\n",
       "        'Male'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496737651.jpg', 'Primate',\n",
       "        'Female'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496740814.jpg', 'Primate',\n",
       "        'Primate'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496749190.jpg', 'Primate',\n",
       "        'Female'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496762191.jpg', 'Primate',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496777203.jpg', 'Primate',\n",
       "        'Female'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496864417.jpg', 'Primate',\n",
       "        'Female'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496884577.jpg', 'Primate',\n",
       "        'Primate'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496891378.jpg', 'Primate',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496896860.jpg', 'Primate',\n",
       "        'Female'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496897801.jpg', 'Primate',\n",
       "        'Primate'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496934526.jpg', 'Primate',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496950484.jpg', 'Primate',\n",
       "        'Primate'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496982577.jpg', 'Primate',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496993668.jpg', 'Primate',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496996700.jpg', 'Primate',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553497005284.jpg', 'Primate',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553497005316.jpg', 'Primate',\n",
       "        'Primate'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553497007920.jpg', 'Primate',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553497027015.jpg', 'Primate',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553497056884.jpg', 'Primate',\n",
       "        'Primate'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553497095620.jpg', 'Primate',\n",
       "        'Male'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553497141603.jpg', 'Primate',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553497149149.jpg', 'Primate',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553497150031.jpg', 'Primate',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553497151184.jpg', 'Primate',\n",
       "        'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/6_img_1553496420740.jpg', 'Primate',\n",
       "        'Female'],\n",
       "       ['..\\\\Images/Student_Test/32.jpg', 'Food', 'Food'],\n",
       "       ['..\\\\Images/Student_Test/33.jpg', 'Food', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/34.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/35.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/36.jpg', 'Food', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/37.jpg', 'Food', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/38.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/39.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/40.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/41.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/42.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/43.jpg', 'Food', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/44.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/46.jpg', 'Food', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/47.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/48.jpg', 'Food', 'Primate'],\n",
       "       ['..\\\\Images/Student_Test/49.jpg', 'Food', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/50.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/51.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/53.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/54.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/0.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/1.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/2.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/3.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/5.jpg', 'Food', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/6.jpg', 'Food', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/7.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/8.jpg', 'Food', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/9.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/10.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/11.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/12.jpg', 'Food', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/13.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/14.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/15.jpg', 'Food', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/17.jpg', 'Food', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/18.jpg', 'Food', 'Food'],\n",
       "       ['..\\\\Images/Student_Test/19.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/20.jpg', 'Food', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/21.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/22.jpg', 'Food', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/23.jpg', 'Food', 'Female'],\n",
       "       ['..\\\\Images/Student_Test/24.jpg', 'Food', 'Food'],\n",
       "       ['..\\\\Images/Student_Test/25.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/26.jpg', 'Food', 'Primate'],\n",
       "       ['..\\\\Images/Student_Test/27.jpg', 'Food', 'Male'],\n",
       "       ['..\\\\Images/Student_Test/28.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/29.jpg', 'Food', 'Rodent'],\n",
       "       ['..\\\\Images/Student_Test/30.jpg', 'Food', 'Rodent']], dtype='<U70')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classified_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02a32e0",
   "metadata": {},
   "source": [
    "# Basic evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5c1ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(classified_data):\n",
    "    confusion_matrix = np.zeros((len(classification_scheme), len(classification_scheme)), dtype=int)\n",
    "    \n",
    "    for row in classified_data[1:] : # Skip the first row which contains column headers\n",
    "        actual_class = row[1]\n",
    "        predicted_class = row[2]\n",
    "        actual_index = classification_scheme.index(actual_class)\n",
    "        predicted_index = classification_scheme.index(predicted_class)\n",
    "        confusion_matrix[predicted_index, actual_index] += 1\n",
    "    sorted_indices = np.argsort(classification_scheme)\n",
    "    sorted_confusion_matrix = confusion_matrix[sorted_indices][:, sorted_indices]\n",
    "\n",
    "    return sorted_confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3a67677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTPs(confusion_matrix):\n",
    "    tps = [confusion_matrix[classification_scheme.index(cls), classification_scheme.index(cls)] for cls in classification_scheme]\n",
    "    return tps\n",
    "\n",
    "def computeFPs(confusion_matrix):\n",
    "    fps = []\n",
    "    for cls in classification_scheme:\n",
    "        col_idx = classification_scheme.index(cls)\n",
    "        fp = sum(confusion_matrix[:, col_idx]) - confusion_matrix[col_idx, col_idx]\n",
    "        fps.append(fp)\n",
    "    return fps\n",
    "\n",
    "def computeFNs(confusion_matrix):\n",
    "    fns = []\n",
    "    for cls in classification_scheme:\n",
    "        row_idx = classification_scheme.index(cls)\n",
    "        fn = sum(confusion_matrix[row_idx, :]) - confusion_matrix[row_idx, row_idx]\n",
    "        fns.append(fn)\n",
    "    return fns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a882915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMacroPrecision(tps, fps, fns, data_size):\n",
    "    precisions = []\n",
    "    for i in range(len(tps)):\n",
    "        if (tps[i] + fps[i]) != 0:\n",
    "            precision = tps[i] / (tps[i] + fps[i])\n",
    "        else:\n",
    "            precision = 0\n",
    "        precisions.append(precision)\n",
    "    macro_precision = sum(precisions) / len(precisions)\n",
    "    return macro_precision\n",
    "\n",
    "def computeMacroRecall(tps, fps, fns, data_size):\n",
    "    recalls = []\n",
    "    for i in range(len(tps)):\n",
    "        if (tps[i] + fns[i]) != 0:\n",
    "            recall = tps[i] / (tps[i] + fns[i])\n",
    "        else:\n",
    "            recall = 0\n",
    "        recalls.append(recall)\n",
    "    macro_recall = sum(recalls) / len(recalls)\n",
    "    return macro_recall\n",
    "\n",
    "def computeMacroFMeasure(computeMacroRecall, computeMacroPrecision):\n",
    "    macro_f_measure = (2*computeMacroPrecision*computeMacroRecall)/(computeMacroPrecision+computeMacroRecall)\n",
    "    return macro_f_measure\n",
    "\n",
    "def computeAccuracy(tps, fps, fns, data_size):\n",
    "    accuracies = []\n",
    "    for i in range(len(tps)):\n",
    "        accuracy = (tps[i] + data_size - (fps[i] + fns[i])) / data_size\n",
    "        accuracies.append(accuracy)\n",
    "    macro_accuracy = sum(accuracies) / len(accuracies)\n",
    "    return macro_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "123e31d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateKNN(classified_data, confusionMatrix):\n",
    "    # Compute the confusion matrix\n",
    "    confusionmatrix = confusion_matrix(classified_data)\n",
    "    classified_data_size = len(classified_data)\n",
    "    # Compute TP, FP, FN for each class\n",
    "    tps = computeTPs(confusionmatrix)\n",
    "    fps = computeFPs(confusionmatrix)\n",
    "    fns = computeFNs(confusionmatrix)\n",
    "    \n",
    "    # Calculate precision, recall, f-measure, and accuracy using macro-average approach\n",
    "    precision = computeMacroPrecision(tps, fps, fns, classified_data_size)\n",
    "    recall = computeMacroRecall(tps, fps, fns, classified_data_size)\n",
    "    f_measure = computeMacroFMeasure(recall,precision)\n",
    "    accuracy = computeAccuracy(tps, fps, fns, classified_data_size)\n",
    "    \n",
    "    # Return the computed measures\n",
    "    return precision, recall, f_measure, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba6f8cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f_measure, accuracy = evaluateKNN(classified_data , confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41852513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.952988047808765"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed102b6b",
   "metadata": {},
   "source": [
    "#  k-fold cross-validation technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7797781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataForCrossValidation(training_data, f):\n",
    "    folds = []\n",
    "    fold_size = len(training_data) // f\n",
    "    remainder = len(training_data) % f\n",
    "    \n",
    "    start_idx = 0\n",
    "    for i in range(1, f + 1):\n",
    "        fold_end = start_idx + fold_size\n",
    "        if i <= remainder:\n",
    "            fold_end += 1\n",
    "        \n",
    "        test_indices = []\n",
    "        train_indices = []\n",
    "        for idx in range(len(training_data)):\n",
    "            if start_idx <= idx < fold_end:\n",
    "                test_indices.append(idx)\n",
    "            else:\n",
    "                train_indices.append(idx)\n",
    "        \n",
    "        training_fold = training_data[train_indices]\n",
    "        testing_fold = training_data[test_indices]\n",
    "        \n",
    "        folds.append([i, training_fold, testing_fold])\n",
    "        start_idx = fold_end\n",
    "    \n",
    "    return folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca740c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateDataFormat(data, f):\n",
    "    # Check if the header is present\n",
    "    header = [\"Path\", \"ActualClass\", \"PredictedClass\", \"FoldNumber\"]\n",
    "    if not np.array_equal(data[0], header):\n",
    "        return False\n",
    "    \n",
    "    # Check if the values in the \"Path\" column are file paths\n",
    "    if any(not isinstance(path, str) for path in data[1:, 0]):\n",
    "        return False\n",
    "    \n",
    "    # Check if the values in the \"ActualClass\" and \"PredictedClass\" columns are classes from the scheme\n",
    "    # (Assuming the class scheme is defined somewhere)\n",
    "    class_scheme = ['Female', 'Male', 'Primate', 'Rodent', 'Food'] # Replace with actual class scheme\n",
    "    if any(cls not in class_scheme for cls in np.unique(data[1:, 1:3])):\n",
    "        return False\n",
    "    \n",
    "    # Check if the values in the \"FoldNumber\" column are integers in [0,f) range\n",
    "    if any(not isinstance(num, int) or num < 0 or num >= f for num in data[1:, 3]):\n",
    "        return False\n",
    "    \n",
    "    # Check if there are as many entries in the \"Path\" column as there are in the other columns\n",
    "    if not all(len(data[1:, 0]) == len(data[1:, i]) for i in range(1, 4)):\n",
    "        return False\n",
    "    \n",
    "    # Check if the number of entries per each integer in [0,f) range for FoldNumber are approximately the same\n",
    "    fold_counts = {i: 0 for i in range(f)}\n",
    "    for fold_num in data[1:, 3]:\n",
    "        fold_counts[fold_num] += 1\n",
    "    max_count = max(fold_counts.values())\n",
    "    min_count = min(fold_counts.values())\n",
    "    if max_count - min_count > 1:\n",
    "        return False\n",
    "    \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7710dfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateCrossValidation(classified_data_list, evaluation_func = evaluateKNN):\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f_measure = 0\n",
    "    total_accuracy = 0\n",
    "    num_rounds = len(classified_data_list)\n",
    "\n",
    "    # Iterate over each round's classified data\n",
    "    for classified_data in classified_data_list:\n",
    "        # Evaluate the classified data using the evaluation function\n",
    "        precision, recall, f_measure, accuracy = evaluation_func(classified_data,confusion_matrix)\n",
    "\n",
    "        # Accumulate the evaluation measures\n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        total_f_measure += f_measure\n",
    "        total_accuracy += accuracy\n",
    "\n",
    "    # Calculate average measures\n",
    "    avg_precision = total_precision / num_rounds\n",
    "    avg_recall = total_recall / num_rounds\n",
    "    avg_f_measure = total_f_measure / num_rounds\n",
    "    avg_accuracy = total_accuracy / num_rounds\n",
    "\n",
    "    return avg_precision, avg_recall, avg_f_measure, avg_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61765edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossEvaluateKNN(training_data, k, measure_func, similarity_flag, f,knn_func= kNN ,split_func= splitDataForCrossValidation ):\n",
    "    # Step 1: Split the data into folds\n",
    "    folds = split_func(training_data, f)\n",
    "    \n",
    "    # Header for processed data\n",
    "    processed = np.array([['Path', 'ActualClass', 'PredictedClass', 'FoldNumber']])\n",
    "    # Step 2: Process each fold\n",
    "    classified_list = []\n",
    "\n",
    "    for fold in folds:\n",
    "        fold_num , train_data, test_data = fold[0] ,fold[1] ,fold[2]\n",
    "\n",
    "        classified_data = knn_func(train_data , 11 , computeMeasure2, False , test_data ,getMostCommonClass , getClassesOfKNearestNeighbours , readAndResize)        \n",
    "        classified_list.append(classified_data)\n",
    "\n",
    "        fold_numbers = np.full((len(classified_data), 1), fold_num)\n",
    "        processed_fold = np.hstack((classified_data, fold_numbers))\n",
    "        processed = np.append(processed, processed_fold, axis=0)\n",
    "\n",
    " \n",
    "    avg_precision, avg_recall, avg_fMeasure, avg_accuracy = evaluateCrossValidation(classified_list ,evaluateKNN )\n",
    "\n",
    "     # The measures are now added to the end. You should invoke validation BEFORE this step.\n",
    "    h = ['avg_precision', 'avg_recall', 'avg_f_measure', 'avg_accuracy']\n",
    "    v = [avg_precision, avg_recall, avg_fMeasure, avg_accuracy]\n",
    "\n",
    "    processed = np.append(processed, [h], axis=0)\n",
    "    processed = np.append(processed, [v], axis=0)\n",
    "\n",
    "    return processed\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01d97377",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = crossEvaluateKNN(train_ndarray , 11 , computeMeasure2 , False , 5 , kNN ,splitDataForCrossValidation  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3a57f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Path', 'ActualClass', 'PredictedClass', 'FoldNumber'],\n",
       "       ['Path', 'ActualClass', 'PredictedClass', '1'],\n",
       "       ['..\\\\Images/Student_Test/generated.photos_v3_0626369.jpg',\n",
       "        'Female', 'Female', '1'],\n",
       "       ...,\n",
       "       ['..\\\\Images/Student_Test/30.jpg', 'Food', 'Rodent', '5'],\n",
       "       ['avg_precision', 'avg_recall', 'avg_f_measure', 'avg_accuracy'],\n",
       "       ['0.5781805555555556', '0.6802508129770668', '0.6250762700278367',\n",
       "        '0.952988047808765']], dtype='<U70')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a5d946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP Environment",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
